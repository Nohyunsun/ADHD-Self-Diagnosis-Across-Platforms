{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYuW5nzTSmOvxo05OTChuc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nohyunsun/ADHD-Self-Diagnosis-Across-Platforms/blob/main/ensemble_sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 성능 향상\n",
        "- TARGET_PER_CLASS를 800~1500으로 키워 성능을 더 끌어올림\n",
        "- (엔진: TF-IDF(word+char) 듀얼 모델 + 소프트보팅 앙상블 → 검증셋에서 macro-F1을 올리도록 클래스별 확률 스케일을 탐욕적 튜닝으로 최적화)\n",
        "\n",
        "=> 핵심: 단일 모델(+중립 편향)보다 소수 클래스 F1이 올라오도록 확률을 클래스별로 미세 조정했어.\n",
        "여전히 데이터 자체 난이도(문맥 중의성, 부정어 등) 때문에 완벽하진 않지만, 중립 쏠림은 확실히 완화된 게 정상."
      ],
      "metadata": {
        "id": "ivG9godkdsQE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJCI1Z2cdUeL"
      },
      "outputs": [],
      "source": [
        "# Fast retry: dual-model ensemble + greedy per-class scaling (3 choices per class), much faster than full grid.\n",
        "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt, joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, f1_score, accuracy_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.utils import resample\n",
        "from caas_jupyter_tools import display_dataframe_to_user\n",
        "\n",
        "OUTDIR = \"/mnt/data\"\n",
        "LABELED_XLSX = \"/mnt/data/korean_sentiment_dataset.xlsx\"\n",
        "PLATFORMS = {\n",
        "    \"youtube\": \"/mnt/data/all_mapped_youtube.xlsx\",\n",
        "    \"blog\": \"/mnt/data/all_mapped_blog.xlsx\",\n",
        "    \"instagram\": \"/mnt/data/all_mapped_instagram.xlsx\",\n",
        "    \"x\": \"/mnt/data/all_mapped_x.xlsx\",\n",
        "}\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "\n",
        "# 1) Load & clean\n",
        "raw = pd.read_excel(LABELED_XLSX)\n",
        "df = raw.loc[1:, [\"Unnamed: 1\",\"Unnamed: 2\"]].rename(columns={\"Unnamed: 1\":\"text\",\"Unnamed: 2\":\"label\"})\n",
        "df = df.dropna(subset=[\"text\",\"label\"]).astype(str)\n",
        "valid = {\"행복\",\"중립\",\"슬픔\",\"공포\",\"혐오\",\"분노\",\"놀람\"}\n",
        "df = df[df[\"label\"].isin(valid)].copy()\n",
        "\n",
        "# 2) Rebalance (target per class 1000 for speed/perf balance)\n",
        "TARGET_PER_CLASS = 1000\n",
        "frames=[]\n",
        "for lab, grp in df.groupby(\"label\"):\n",
        "    if len(grp) >= TARGET_PER_CLASS:\n",
        "        frames.append(grp.sample(n=TARGET_PER_CLASS, random_state=42))\n",
        "    else:\n",
        "        frames.append(pd.concat([grp, resample(grp, replace=True, n_samples=TARGET_PER_CLASS-len(grp), random_state=42)]))\n",
        "dfb = pd.concat(frames).sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# 3) Split\n",
        "Xtr_text, Xva_text, ytr_str, yva_str = train_test_split(\n",
        "    dfb[\"text\"].values, dfb[\"label\"].values, test_size=0.2, random_state=42, stratify=dfb[\"label\"].values\n",
        ")\n",
        "\n",
        "# 4) Vectorizers (smaller feature caps for speed)\n",
        "vec_char = TfidfVectorizer(analyzer=\"char\", ngram_range=(2,5), min_df=3, max_df=0.995,\n",
        "                           sublinear_tf=True, max_features=15000)\n",
        "vec_word = TfidfVectorizer(analyzer=\"word\", ngram_range=(1,2), min_df=2, max_df=0.99,\n",
        "                           sublinear_tf=True, max_features=20000)\n",
        "Xtr_c = vec_char.fit_transform(Xtr_text); Xva_c = vec_char.transform(Xva_text)\n",
        "Xtr_w = vec_word.fit_transform(Xtr_text); Xva_w = vec_word.transform(Xva_text)\n",
        "\n",
        "# 5) Labels & weights\n",
        "le = LabelEncoder(); ytr = le.fit_transform(ytr_str); yva = le.transform(yva_str)\n",
        "classes = np.unique(ytr)\n",
        "cw = compute_class_weight(class_weight=\"balanced\", classes=classes, y=ytr)\n",
        "sw = cw[ytr]\n",
        "\n",
        "# 6) Train probabilistic classifiers\n",
        "clf_c = SGDClassifier(loss=\"log_loss\", alpha=4e-4, random_state=42)\n",
        "clf_w = SGDClassifier(loss=\"log_loss\", alpha=6e-4, random_state=42)\n",
        "clf_c.partial_fit(Xtr_c, ytr, classes=classes, sample_weight=sw)\n",
        "clf_w.partial_fit(Xtr_w, ytr, classes=classes, sample_weight=sw)\n",
        "\n",
        "proba_c = clf_c.predict_proba(Xva_c)\n",
        "proba_w = clf_w.predict_proba(Xva_w)\n",
        "proba = 0.6*proba_c + 0.4*proba_w\n",
        "\n",
        "# 7) Greedy per-class scaling (scales in {0.9, 1.0, 1.1})\n",
        "scales = np.ones(len(classes))\n",
        "choices = [0.9, 1.0, 1.1]\n",
        "def eval_scales(s):\n",
        "    p = proba * s[None,:]\n",
        "    p = p / p.sum(axis=1, keepdims=True)\n",
        "    pred = p.argmax(1)\n",
        "    return f1_score(yva, pred, average=\"macro\")\n",
        "\n",
        "base = eval_scales(scales)\n",
        "improved = True\n",
        "while improved:\n",
        "    improved = False\n",
        "    for k in range(len(classes)):\n",
        "        best_local = base; best_val = scales[k]\n",
        "        for v in choices:\n",
        "            test = scales.copy(); test[k] = v\n",
        "            f1m = eval_scales(test)\n",
        "            if f1m > best_local + 1e-4:\n",
        "                best_local, best_val = f1m, v\n",
        "        if best_val != scales[k]:\n",
        "            scales[k] = best_val\n",
        "            base = best_local\n",
        "            improved = True\n",
        "\n",
        "# Final preds\n",
        "p_final = proba * scales[None,:]\n",
        "p_final = p_final / p_final.sum(axis=1, keepdims=True)\n",
        "yva_pred = p_final.argmax(1)\n",
        "val_acc = accuracy_score(yva, yva_pred)\n",
        "val_f1 = f1_score(yva, yva_pred, average=\"macro\")\n",
        "report_txt = classification_report(yva, yva_pred, target_names=le.classes_, digits=4, zero_division=0)\n",
        "\n",
        "# Save report & confusion\n",
        "with open(f\"{OUTDIR}/ensemble_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(f\"Validation Accuracy: {val_acc:.4f}\\nMacro F1: {val_f1:.4f}\\nClass scales: {scales.tolist()}\\n\\n{report_txt}\")\n",
        "\n",
        "cm = confusion_matrix(yva_str, le.inverse_transform(yva_pred), labels=list(le.classes_))\n",
        "fig, ax = plt.subplots(figsize=(7,6))\n",
        "ConfusionMatrixDisplay(cm, display_labels=list(le.classes_)).plot(ax=ax, xticks_rotation=45, colorbar=False)\n",
        "plt.title(\"Confusion Matrix (Greedy-scaled Ensemble)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{OUTDIR}/ensemble_confusion_matrix.png\", dpi=150, bbox_inches=\"tight\"); plt.close()\n",
        "\n",
        "# Save artifacts\n",
        "joblib.dump(clf_c, f\"{OUTDIR}/clf_char.pkl\")\n",
        "joblib.dump(clf_w, f\"{OUTDIR}/clf_word.pkl\")\n",
        "joblib.dump(vec_char, f\"{OUTDIR}/vec_char.pkl\")\n",
        "joblib.dump(vec_word, f\"{OUTDIR}/vec_word.pkl\")\n",
        "joblib.dump(le, f\"{OUTDIR}/label_encoder.pkl\")\n",
        "np.save(f\"{OUTDIR}/class_scales.npy\", scales)\n",
        "\n",
        "# 8) Platform predictions with ensemble\n",
        "def detect_text_col(d):\n",
        "    cand = [c for c in d.columns if str(c).lower() in [\"text\",\"content\",\"body\",\"본문\",\"내용\",\"sentence\",\"utterance\",\"comment\",\"댓글\"]]\n",
        "    if cand: return cand[0]\n",
        "    obj = [c for c in d.columns if d[c].dtype=='O']\n",
        "    return obj[0] if obj else d.columns[0]\n",
        "\n",
        "def predict_platform(path, name, limit=8000):\n",
        "    d = pd.read_excel(path)\n",
        "    tc = detect_text_col(d)\n",
        "    sub = d[[tc]].dropna().rename(columns={tc:\"text\"}).copy()\n",
        "    if len(sub) > limit: sub = sub.head(limit).copy()\n",
        "    sub[\"text\"] = sub[\"text\"].astype(str).str.strip()\n",
        "    Xc = vec_char.transform(sub[\"text\"].values)\n",
        "    Xw = vec_word.transform(sub[\"text\"].values)\n",
        "    pc = clf_c.predict_proba(Xc); pw = clf_w.predict_proba(Xw)\n",
        "    p = (0.6*pc + 0.4*pw) * scales[None,:]\n",
        "    p = p / p.sum(axis=1, keepdims=True)\n",
        "    y_idx = p.argmax(1)\n",
        "    sub[\"pred_emotion\"] = le.inverse_transform(y_idx)\n",
        "    dist = sub[\"pred_emotion\"].value_counts().rename_axis(\"emotion\").reset_index(name=\"count\")\n",
        "    dist[\"percent\"] = (dist[\"count\"]/dist[\"count\"].sum()*100).round(2)\n",
        "    base = f\"{OUTDIR}/ensemble_{name}\"\n",
        "    sub.to_csv(base+\"_predictions.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "    dist.to_csv(base+\"_distribution.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.bar(dist[\"emotion\"], dist[\"count\"])\n",
        "    plt.title(f\"{name}: Emotion Distribution (Ensemble)\")\n",
        "    plt.xlabel(\"Emotion\"); plt.ylabel(\"Count\"); plt.tight_layout()\n",
        "    plt.savefig(base+\"_distribution.png\", dpi=150, bbox_inches=\"tight\"); plt.close()\n",
        "    return {\"platform\": name, \"n_texts_used\": len(sub), \"text_col\": tc,\n",
        "            \"predictions_csv\": base+\"_predictions.csv\", \"distribution_csv\": base+\"_distribution.csv\", \"chart_png\": base+\"_distribution.png\"}\n",
        "\n",
        "rows=[]\n",
        "for k, p in PLATFORMS.items():\n",
        "    if os.path.exists(p):\n",
        "        try:\n",
        "            rows.append(predict_platform(p, k))\n",
        "        except Exception as e:\n",
        "            rows.append({\"platform\": k, \"error\": str(e)})\n",
        "    else:\n",
        "        rows.append({\"platform\": k, \"error\": \"file not found\"})\n",
        "\n",
        "overview = pd.DataFrame(rows)\n",
        "display_dataframe_to_user(\"Ensemble predictions overview (improved performance, greedy scaling)\", overview)\n",
        "\n",
        "(f\"{OUTDIR}/ensemble_report.txt\", f\"{OUTDIR}/ensemble_confusion_matrix.png\", rows)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 성능 지표"
      ],
      "metadata": {
        "id": "u5oH1p9BkohG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| 감정(Label) | Precision | Recall | F1-score | Support |\n",
        "| --------- | --------- | ------ | -------- | ------- |\n",
        "| 공포        | 0.9471    | 0.9850 | 0.9657   | 200     |\n",
        "| 놀람        | 0.5581    | 0.6000 | 0.5783   | 200     |\n",
        "| 분노        | 0.5550    | 0.6050 | 0.5789   | 200     |\n",
        "| 슬픔        | 0.5314    | 0.4650 | 0.4960   | 200     |\n",
        "| 중립        | 0.4021    | 0.3900 | 0.3959   | 200     |\n",
        "| 행복        | 0.6020    | 0.5900 | 0.5960   | 200     |\n",
        "| 혐오        | 0.9072    | 0.8800 | 0.8934   | 200     |\n"
      ],
      "metadata": {
        "id": "MSnCPvajkhAn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| 항목                  | 값                                   |\n",
        "| ------------------- | ----------------------------------- |\n",
        "| Validation Accuracy | **0.6450**                          |\n",
        "| Macro F1            | **0.6435**                          |\n",
        "| Class Scales        | [0.9, 1.1, 1.0, 1.0, 1.0, 1.0, 1.0] |\n",
        "| Accuracy (전체)       | 0.6450                              |\n",
        "| Macro 평균 Precision  | 0.6433                              |\n",
        "| Macro 평균 Recall     | 0.6450                              |\n",
        "| Macro 평균 F1-score   | 0.6435                              |\n"
      ],
      "metadata": {
        "id": "SQ4nLITxkhu5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 앙상블 모델(ensemble_char+word) 과 검증 데이터(yva_pred, yva_true)를 활용\n",
        "- 오분류 분석\n",
        "- 대표 문장 추출"
      ],
      "metadata": {
        "id": "nEpSsNFCed_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recreate the two requested result sets:\n",
        "# (1) Platform-wise Top-50 representative sentences per emotion (filtered & de-duplicated)\n",
        "# (5) Threshold tuning tables for boosting recall of 혐오/공포 (grid + comparison)\n",
        "import os, re, textwrap, numpy as np, pandas as pd, joblib, matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import precision_recall_fscore_support, f1_score, accuracy_score, classification_report\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.utils import resample\n",
        "from caas_jupyter_tools import display_dataframe_to_user\n",
        "\n",
        "OUTDIR = \"/mnt/data\"\n",
        "LABELED_XLSX = \"/mnt/data/korean_sentiment_dataset.xlsx\"\n",
        "PLATFORMS = {\n",
        "    \"youtube\": \"/mnt/data/all_mapped_youtube.xlsx\",\n",
        "    \"blog\": \"/mnt/data/all_mapped_blog.xlsx\",\n",
        "    \"instagram\": \"/mnt/data/all_mapped_instagram.xlsx\",\n",
        "    \"x\": \"/mnt/data/all_mapped_x.xlsx\",\n",
        "}\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "\n",
        "# -------------------- Load labeled data --------------------\n",
        "분\n",
        "df = raw.loc[1:, [\"Unnamed: 1\",\"Unnamed: 2\"]].rename(columns={\"Unnamed: 1\":\"text\",\"Unnamed: 2\":\"label\"})\n",
        "df = df.dropna(subset=[\"text\",\"label\"]).astype(str)\n",
        "valid_labels = [\"행복\",\"중립\",\"슬픔\",\"공포\",\"혐오\",\"분노\",\"놀람\"]\n",
        "df = df[df[\"label\"].isin(valid_labels)].copy()\n",
        "\n",
        "# -------------------- Try to load ensemble artifacts; else train fallback --------------------\n",
        "use_ensemble = all(os.path.exists(p) for p in [\n",
        "    f\"{OUTDIR}/clf_char.pkl\",\n",
        "    f\"{OUTDIR}/clf_word.pkl\",\n",
        "    f\"{OUTDIR}/vec_char.pkl\",\n",
        "    f\"{OUTDIR}/vec_word.pkl\",\n",
        "    f\"{OUTDIR}/label_encoder.pkl\",\n",
        "    f\"{OUTDIR}/class_scales.npy\",\n",
        "])\n",
        "\n",
        "if use_ensemble:\n",
        "    clf_c = joblib.load(f\"{OUTDIR}/clf_char.pkl\")\n",
        "    clf_w = joblib.load(f\"{OUTDIR}/clf_word.pkl\")\n",
        "    vec_c = joblib.load(f\"{OUTDIR}/vec_char.pkl\")\n",
        "    vec_w = joblib.load(f\"{OUTDIR}/vec_word.pkl\")\n",
        "    le = joblib.load(f\"{OUTDIR}/label_encoder.pkl\")\n",
        "    base_scales = np.load(f\"{OUTDIR}/class_scales.npy\")\n",
        "    labels = list(le.classes_)\n",
        "else:\n",
        "    # Train a quick balanced single-model fallback (char TF-IDF + SGD log_loss)\n",
        "    TARGET_PER_CLASS = 1000\n",
        "    frames=[]\n",
        "    for lab, grp in df.groupby(\"label\"):\n",
        "        if len(grp) >= TARGET_PER_CLASS:\n",
        "            frames.append(grp.sample(n=TARGET_PER_CLASS, random_state=42))\n",
        "        else:\n",
        "            frames.append(pd.concat([grp, resample(grp, replace=True, n_samples=TARGET_PER_CLASS-len(grp), random_state=42)]))\n",
        "    df_bal = pd.concat(frames).sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
        "    Xtr_text, Xva_text, ytr_str, yva_str = train_test_split(\n",
        "        df_bal[\"text\"].values, df_bal[\"label\"].values, test_size=0.2, random_state=42, stratify=df_bal[\"label\"].values\n",
        "    )\n",
        "    le = LabelEncoder(); ytr = le.fit_transform(ytr_str); yva = le.transform(yva_str)\n",
        "    labels = list(le.classes_)\n",
        "    vec_c = TfidfVectorizer(analyzer=\"char\", ngram_range=(2,5), min_df=3, max_df=0.995, sublinear_tf=True, max_features=20000)\n",
        "    Xtr_c = vec_c.fit_transform(Xtr_text); Xva_c = vec_c.transform(Xva_text)\n",
        "    classes = np.unique(ytr)\n",
        "    cw = compute_class_weight(class_weight=\"balanced\", classes=classes, y=ytr)\n",
        "    sw = cw[ytr]\n",
        "    clf_c = SGDClassifier(loss=\"log_loss\", alpha=4e-4, random_state=42)\n",
        "    clf_c.partial_fit(Xtr_c, ytr, classes=classes, sample_weight=sw)\n",
        "    # Mimic ensemble using only char model; define dummy word vectorizer/model\n",
        "    clf_w = None; vec_w = None\n",
        "    base_scales = np.ones(len(labels))\n",
        "\n",
        "# -------------------- Validation split (for threshold tuning) --------------------\n",
        "# Use original df (not balanced) for realistic validation\n",
        "Xtr_text_v, Xva_text_v, ytr_str_v, yva_str_v = train_test_split(\n",
        "    df[\"text\"].values, df[\"label\"].values, test_size=0.2, random_state=42, stratify=df[\"label\"].values\n",
        ")\n",
        "# vectorize val and get probabilities\n",
        "Xc_val = vec_c.transform(Xva_text_v)\n",
        "pc_val = clf_c.predict_proba(Xc_val)\n",
        "if clf_w is not None:\n",
        "    Xw_val = vec_w.transform(Xva_text_v)\n",
        "    pw_val = clf_w.predict_proba(Xw_val)\n",
        "    proba_val = (0.6*pc_val + 0.4*pw_val)\n",
        "else:\n",
        "    proba_val = pc_val\n",
        "proba_val = proba_val * base_scales[None,:]\n",
        "proba_val = proba_val / proba_val.sum(axis=1, keepdims=True)\n",
        "yva_idx = np.array([labels.index(y) for y in yva_str_v])\n",
        "\n",
        "# -------------------- (1) Platform-wise Top-50 representative sentences --------------------\n",
        "bad_terms = [\"씨발\",\"ㅅㅂ\",\"ㅄ\",\"개새\",\"좆\",\"병신\",\"새끼\",\"니엄마\",\"sex\",\"섹스\",\"fuck\",\"shit\",\"좇\",\"씹\",\"꺼져\",\"좆같\",\"미친년\",\"강간\",\"강제\",\"n번방\"]\n",
        "def normalize_text(s): return re.sub(r\"\\s+\", \" \", str(s).strip())\n",
        "def is_clean(s):\n",
        "    low = s.lower()\n",
        "    if len(s) < 5: return False\n",
        "    for t in bad_terms:\n",
        "        if t.lower() in low: return False\n",
        "    return True\n",
        "\n",
        "def detect_text_col(d):\n",
        "    cand = [c for c in d.columns if str(c).lower() in [\"text\",\"content\",\"body\",\"본문\",\"내용\",\"sentence\",\"utterance\",\"comment\",\"댓글\",\"caption\",\"title\"]]\n",
        "    if cand: return cand[0]\n",
        "    obj = d.select_dtypes(include=\"object\").columns.tolist()\n",
        "    return obj[0] if obj else d.columns[0]\n",
        "\n",
        "def representative_for_platform(path, platform_name, topk=50):\n",
        "    if not os.path.exists(path):\n",
        "        return None\n",
        "    d = pd.read_excel(path)\n",
        "    tc = detect_text_col(d)\n",
        "    sub = d[[tc]].dropna().rename(columns={tc:\"text\"}).copy()\n",
        "    sub[\"text\"] = sub[\"text\"].astype(str).map(normalize_text)\n",
        "    sub = sub[sub[\"text\"].map(is_clean)]\n",
        "    if sub.empty:\n",
        "        out_csv = f\"{OUTDIR}/rep_top50_{platform_name}.csv\"\n",
        "        pd.DataFrame(columns=[\"platform\",\"emotion\",\"rank\",\"prob\",\"text\"]).to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
        "        return out_csv\n",
        "    Xc = vec_c.transform(sub[\"text\"].values)\n",
        "    pc = clf_c.predict_proba(Xc)\n",
        "    if clf_w is not None:\n",
        "        Xw = vec_w.transform(sub[\"text\"].values)\n",
        "        pw = clf_w.predict_proba(Xw)\n",
        "        p = (0.6*pc + 0.4*pw)\n",
        "    else:\n",
        "        p = pc\n",
        "    p = p * base_scales[None,:]\n",
        "    p = p / p.sum(axis=1, keepdims=True)\n",
        "    rows = []\n",
        "    for li, lab in enumerate(labels):\n",
        "        order = np.argsort(-p[:, li])\n",
        "        seen = set(); kept=0\n",
        "        for idx in order:\n",
        "            txt = sub[\"text\"].iloc[idx]\n",
        "            if txt in seen: continue\n",
        "            seen.add(txt)\n",
        "            rows.append({\"platform\": platform_name, \"emotion\": lab, \"rank\": kept+1, \"prob\": round(float(p[idx, li]),4), \"text\": txt})\n",
        "            kept += 1\n",
        "            if kept >= topk: break\n",
        "    rep_df = pd.DataFrame(rows)\n",
        "    out_csv = f\"{OUTDIR}/rep_top50_{platform_name}.csv\"\n",
        "    rep_df.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
        "    return out_csv\n",
        "\n",
        "rep_paths = {}\n",
        "for name, pth in PLATFORMS.items():\n",
        "    rep_paths[name] = representative_for_platform(pth, name, topk=50)\n",
        "\n",
        "# -------------------- (5) Threshold tuning for 혐오/공포 recall ↑ --------------------\n",
        "def eval_with_boost(bh=1.0, bf=1.0):\n",
        "    scales = np.ones(len(labels))\n",
        "    if \"혐오\" in labels: scales[labels.index(\"혐오\")] = bh\n",
        "    if \"공포\" in labels: scales[labels.index(\"공포\")] = bf\n",
        "    p = proba_val * scales[None,:]\n",
        "    p = p / p.sum(axis=1, keepdims=True)\n",
        "    pred = p.argmax(1)\n",
        "    pcls, rcls, f1cls, supp = precision_recall_fscore_support(yva_idx, pred, labels=range(len(labels)), zero_division=0)\n",
        "    macro = f1_score(yva_idx, pred, average=\"macro\")\n",
        "    acc = accuracy_score(yva_idx, pred)\n",
        "    dfm = pd.DataFrame({\"label\": labels, \"precision\": np.round(pcls,4), \"recall\": np.round(rcls,4), \"f1\": np.round(f1cls,4), \"support\": supp})\n",
        "    return pred, dfm, macro, acc\n",
        "\n",
        "grid = [1.0, 1.1, 1.2, 1.3, 1.4, 1.5]\n",
        "records = []\n",
        "best_macro=-1; best=(1.0,1.0,None)\n",
        "for bh in grid:\n",
        "    for bf in grid:\n",
        "        _, dfm, macro, acc = eval_with_boost(bh, bf)\n",
        "        hate_rec = float(dfm.loc[dfm[\"label\"]==\"혐오\",\"recall\"].values[0]) if \"혐오\" in labels else np.nan\n",
        "        fear_rec = float(dfm.loc[dfm[\"label\"]==\"공포\",\"recall\"].values[0]) if \"공포\" in labels else np.nan\n",
        "        records.append({\"boost_혐오\":bh, \"boost_공포\":bf, \"macroF1\":macro, \"acc\":acc, \"recall_혐오\":hate_rec, \"recall_공포\":fear_rec})\n",
        "        if macro > best_macro:\n",
        "            best_macro = macro; best=(bh, bf, dfm)\n",
        "\n",
        "tune_df = pd.DataFrame(records).sort_values([\"macroF1\",\"recall_혐오\",\"recall_공포\"], ascending=False)\n",
        "tune_csv = f\"{OUTDIR}/threshold_tuning_grid.csv\"\n",
        "tune_df.to_csv(tune_csv, index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "_, base_dfm, base_macro, base_acc = eval_with_boost(1.0,1.0)\n",
        "bh,bf,best_dfm = best\n",
        "comp = base_dfm.merge(best_dfm, on=\"label\", suffixes=(\"_base\",\"_tuned\"))\n",
        "comp = comp[[\"label\",\"precision_base\",\"recall_base\",\"f1_base\",\"precision_tuned\",\"recall_tuned\",\"f1_tuned\",\"support_base\"]].rename(columns={\"support_base\":\"support\"})\n",
        "comp_csv = f\"{OUTDIR}/threshold_tuning_comparison.csv\"\n",
        "comp.to_csv(comp_csv, index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "# Show small previews\n",
        "preview = pd.DataFrame({\n",
        "    \"rep_top50_youtube\":[rep_paths[\"youtube\"]],\n",
        "    \"rep_top50_blog\":[rep_paths[\"blog\"]],\n",
        "    \"rep_top50_instagram\":[rep_paths[\"instagram\"]],\n",
        "    \"rep_top50_x\":[rep_paths[\"x\"]],\n",
        "    \"threshold_grid\":[tune_csv],\n",
        "    \"threshold_compare\":[comp_csv],\n",
        "})\n",
        "display_dataframe_to_user(\"생성된 결과 파일 경로 미리보기\", preview)\n",
        "\n",
        "(rep_paths, tune_csv, comp_csv, use_ensemble)\n"
      ],
      "metadata": {
        "id": "8qGjJDMzek3V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}